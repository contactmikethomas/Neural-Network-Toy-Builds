{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is somewhat similiar to the classic MNIST number classificaiton project, but with a larger and potentially more interesting dataset. Details here: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Citation: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n",
    "\n",
    "We will be using Keras to build a convolutional neural network and predict house numbers from pictures. \n",
    "\n",
    "As with all of the toy builds, this code will follow the same structure:  \n",
    "\n",
    "    Importing Packages\n",
    "    Preparing the Data  \n",
    "    Building the Neural Network  \n",
    "    Testing the Neural Network   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Reading in MATLAB files\n",
    "import scipy.io \n",
    "\n",
    "# Preparing the Data\n",
    "import numpy as np \n",
    "from PIL import ImageOps, Image # Equalise the image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Building and Testing the Network\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input = scipy.io.loadmat('train_32x32.mat')\n",
    "\n",
    "#Process Image Data\n",
    "def process_image(image_array):\n",
    "    \n",
    "    img_in = Image.fromarray(image_array)\n",
    "    img_equalised = ImageOps.equalize(img_in, mask=None)\n",
    "    img_final = np.array(img_equalised, dtype=np.float32)\n",
    "    \n",
    "    return img_final\n",
    "\n",
    "all_images = []\n",
    "\n",
    "for i in range(73257):\n",
    "    new_image = []\n",
    "    for j in range(32):\n",
    "        new_row = []\n",
    "        for k in range(32):\n",
    "            new_row.append([training_input['X'][j][k][0][i], training_input['X'][j][k][1][i], training_input['X'][j][k][2][i]])\n",
    "        new_image.append(new_row)        \n",
    "    all_images.append(process_image(np.asarray(new_image))/255)\n",
    "    \n",
    "all_images_array = np.asarray(all_images)\n",
    "\n",
    "#Process Tags\n",
    "all_tags = []\n",
    "for i in range(73257):\n",
    "    all_tags.append(training_input['y'][i][0])\n",
    "\n",
    "all_tags_array = np.asarray(all_tags)\n",
    "\n",
    "# Label encoding tags\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(all_tags_array.reshape(-1))\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# One hot encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images_array, onehot_encoded, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (58605, 32, 32, 3)\n",
      "y_train shape: (58605, 10)\n",
      "58605 Training samples\n",
      "14652 Testing samples\n"
     ]
    }
   ],
   "source": [
    "#This code is largely borrowed from Keras' MNIST example.\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "x_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'Training samples')\n",
    "print(x_test.shape[0], 'Testing samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58605 samples, validate on 14652 samples\n",
      "Epoch 1/15\n",
      "58605/58605 [==============================] - 54s 923us/step - loss: 0.7840 - acc: 0.7565 - val_loss: 0.5353 - val_acc: 0.8419\n",
      "Epoch 2/15\n",
      "58605/58605 [==============================] - 54s 925us/step - loss: 0.5006 - acc: 0.8537 - val_loss: 0.4892 - val_acc: 0.8548\n",
      "Epoch 3/15\n",
      "58605/58605 [==============================] - 54s 919us/step - loss: 0.4565 - acc: 0.8684 - val_loss: 0.4766 - val_acc: 0.8588\n",
      "Epoch 4/15\n",
      "58605/58605 [==============================] - 54s 929us/step - loss: 0.4298 - acc: 0.8757 - val_loss: 0.4618 - val_acc: 0.8671\n",
      "Epoch 5/15\n",
      "58605/58605 [==============================] - 55s 931us/step - loss: 0.4081 - acc: 0.8811 - val_loss: 0.4343 - val_acc: 0.8725\n",
      "Epoch 6/15\n",
      "58605/58605 [==============================] - 55s 934us/step - loss: 0.3935 - acc: 0.8853 - val_loss: 0.4308 - val_acc: 0.8741\n",
      "Epoch 7/15\n",
      "58605/58605 [==============================] - 54s 925us/step - loss: 0.3796 - acc: 0.8901 - val_loss: 0.4281 - val_acc: 0.8759\n",
      "Epoch 8/15\n",
      "58605/58605 [==============================] - 54s 922us/step - loss: 0.3683 - acc: 0.8919 - val_loss: 0.4346 - val_acc: 0.8723\n",
      "Epoch 9/15\n",
      "58605/58605 [==============================] - 54s 921us/step - loss: 0.3585 - acc: 0.8959 - val_loss: 0.4307 - val_acc: 0.8752\n",
      "Epoch 10/15\n",
      "58605/58605 [==============================] - 54s 922us/step - loss: 0.3492 - acc: 0.8986 - val_loss: 0.4266 - val_acc: 0.8775\n",
      "Epoch 11/15\n",
      "58605/58605 [==============================] - 54s 922us/step - loss: 0.3417 - acc: 0.9007 - val_loss: 0.4342 - val_acc: 0.8729\n",
      "Epoch 12/15\n",
      "58605/58605 [==============================] - 54s 930us/step - loss: 0.3329 - acc: 0.9030 - val_loss: 0.4463 - val_acc: 0.8705\n",
      "Epoch 13/15\n",
      "58605/58605 [==============================] - 55s 931us/step - loss: 0.3281 - acc: 0.9046 - val_loss: 0.4361 - val_acc: 0.8703\n",
      "Epoch 14/15\n",
      "58605/58605 [==============================] - 54s 926us/step - loss: 0.3220 - acc: 0.9048 - val_loss: 0.4315 - val_acc: 0.8758\n",
      "Epoch 15/15\n",
      "58605/58605 [==============================] - 55s 933us/step - loss: 0.3164 - acc: 0.9079 - val_loss: 0.4400 - val_acc: 0.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b24fa47b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test data:\n",
      "Test loss: 0.4400208691023687\n",
      "Test accuracy: 0.8736691236853957\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test data:\")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_images_array shape: (26032, 32, 32, 3)\n",
      "val_onehot_encoded shape: (26032, 10)\n",
      "26032 Training samples\n"
     ]
    }
   ],
   "source": [
    "validation_input = scipy.io.loadmat('test_32x32.mat')\n",
    "\n",
    "#Process Image Data\n",
    "def process_image(image_array):\n",
    "    \n",
    "    img_in = Image.fromarray(image_array)\n",
    "    img_equalised = ImageOps.equalize(img_in, mask=None)\n",
    "    img_final = np.array(img_equalised, dtype=np.float32)\n",
    "    \n",
    "    return img_final\n",
    "\n",
    "val_images = []\n",
    "\n",
    "for i in range(26032):\n",
    "    new_image = []\n",
    "    for j in range(32):\n",
    "        new_row = []\n",
    "        for k in range(32):\n",
    "            new_row.append([validation_input['X'][j][k][0][i], validation_input['X'][j][k][1][i], validation_input['X'][j][k][2][i]])\n",
    "        new_image.append(new_row)        \n",
    "    val_images.append(process_image(np.asarray(new_image))/255)\n",
    "    \n",
    "val_images_array = np.asarray(val_images)\n",
    "\n",
    "#Process Tags\n",
    "val_tags = []\n",
    "for i in range(26032):\n",
    "    val_tags.append(validation_input['y'][i][0])\n",
    "\n",
    "val_tags_array = np.asarray(val_tags)\n",
    "\n",
    "# Label encoding tags\n",
    "val_label_encoder = LabelEncoder()\n",
    "val_integer_encoded = val_label_encoder.fit_transform(val_tags_array.reshape(-1))\n",
    "val_label_mapping = dict(zip(val_label_encoder.classes_, val_label_encoder.transform(val_label_encoder.classes_)))\n",
    "\n",
    "# One hot encoding\n",
    "val_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "val_integer_encoded = val_integer_encoded.reshape(len(val_integer_encoded), 1)\n",
    "val_onehot_encoded = val_onehot_encoder.fit_transform(val_integer_encoded)\n",
    "\n",
    "#Finalise Validation Fample:\n",
    "val_images_array = val_images_array.reshape(val_images_array.shape[0], img_rows, img_cols, 3)\n",
    "val_images_array = val_images_array.astype('float32')\n",
    "\n",
    "print('val_images_array shape:', val_images_array.shape)\n",
    "print('val_onehot_encoded shape:', val_onehot_encoded.shape)\n",
    "print(val_images_array.shape[0], 'Training samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test data:\n",
      "Test loss: 0.5260765965073183\n",
      "Test accuracy: 0.8508758451137062\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on test data:\")\n",
    "score = model.evaluate(val_images_array, val_onehot_encoded, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
